# CartPole DQN ğŸ®

An implementation of **Deep Qâ€‘Network (DQN)** to solve the classic **CartPoleâ€‘v1** environment from [Gymnasium](https://gymnasium.farama.org/).  
Built with **PyTorch**, this project demonstrates reinforcement learning fundamentals: replay buffer, epsilonâ€‘greedy exploration, target network updates, and training loop.

---

## ğŸš€ Features
- DQN agent implemented in PyTorch
- Experience Replay Buffer
- Epsilonâ€‘greedy exploration strategy
- Target network with soft/hard updates
- Training loop with reward tracking
- Evaluation script with video recording of the trained agent

---

## ğŸ“‚ Project Structure

<br>

cartpole-dqn/ â”‚<br>â”œâ”€â”€ README.md # Project overview, setup, usage instructions <br>â”œâ”€â”€ requirements.txt # Python dependencies <br>â”œâ”€â”€ .gitignore # Ignore checkpoints, videos, etc. <br>â”‚ <br>â”œâ”€â”€ src/ # Source code <br>â”‚ <br>â”œâ”€â”€ init.py â”‚ <br>â”œâ”€â”€ dqn.py # DQN network definition <br>â”‚ <br>â”œâ”€â”€ replay_buffer.py # Replay buffer implementation <br>â”‚ <br>â”œâ”€â”€ train.py # Training loop <br>â”‚ <br>â”œâ”€â”€ test.py # Evaluation / rendering loop <br>â”‚ â””â”€â”€ utils.py # Helper functions (plotting, epsilon schedule, etc.) <br>â”‚ <br>â”œâ”€â”€ notebooks/ # Jupyter/Colab notebooks <br>â”‚ â””â”€â”€ DQN_CartPole.ipynb # Exploratory notebook <br>â”‚ <br>â”œâ”€â”€ results/ # Logs, plots, saved models <br>â”‚ <br>â”œâ”€â”€ models/ # Saved checkpoints (.pth files) <br>â”‚ <br>â”œâ”€â”€ videos/ # Recorded agent gameplay <br>â”‚ â””â”€â”€ plots/ # Reward curves, training metrics <br>â”‚ â””â”€â”€ LICENSE # License file (MIT, Apache 2.0, etc.)
---

## âš™ï¸ Installation
Clone the repo and install dependencies:

```bash
git clone https://github.com/aminishereai/cartpole-dqn-.git
cd cartpole-dqn-
pip install -r requirements.txt

